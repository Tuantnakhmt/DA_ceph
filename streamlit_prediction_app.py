import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import time
import datetime

import boto3
import os
from io import StringIO

# MinIO Configuration
MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT", "http://minio:9000")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "minioadmin")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "minioadmin")
MINIO_BUCKET = os.getenv("MINIO_BUCKET", "crawled-data")

s3 = boto3.client(
    's3',
    endpoint_url=MINIO_ENDPOINT,
    aws_access_key_id=MINIO_ACCESS_KEY,
    aws_secret_access_key=MINIO_SECRET_KEY,
)

@st.cache_data
def load_data_from_minio(file_key):
    """Load data from MinIO."""
    response = s3.get_object(Bucket=MINIO_BUCKET, Key=file_key)
    data = pd.read_csv(StringIO(response['Body'].read().decode('utf-8')))
    return data

st.title("Dashboard Ph√¢n T√≠ch D·ª± ƒêo√°n")
st.write("B·∫£ng ƒëi·ªÅu khi·ªÉn t·ª± ƒë·ªông c·∫≠p nh·∫≠t k·∫øt qu·∫£ d·ª± ƒëo√°n, ph√¢n t√≠ch ph·∫ßn d∆∞ v√† ƒë·ªô quan tr·ªçng ƒë·∫∑c tr∆∞ng.")

# Load Data from MinIO
st.info("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ MinIO...")
try:
    # data = load_data_from_minio("data/Ingestion/Financial_with_Sentiment.csv")
    data = load_data_from_minio("data/Ingestion/Financial_with_Sentiment.csv")
    data['Time_Close'] = pd.to_datetime(data['Time_Close'], errors='coerce')
    data['ValueTrading'] = pd.to_numeric(data['ValueTrading'], errors='coerce')
    # data['VolumeTrading'] = pd.to_numeric(data['VolumeTrading'].str.replace(',', ''), errors='coerce')
    # Ensure VolumeTrading can handle non-string values
    if data['VolumeTrading'].dtype == 'object':
        data['VolumeTrading'] = pd.to_numeric(data['VolumeTrading'].str.replace(',', ''), errors='coerce')
    else:
        data['VolumeTrading'] = pd.to_numeric(data['VolumeTrading'], errors='coerce')

    st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
except Exception as e:
    st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ MinIO: {e}")
    st.stop()

# Sidebar Filters
st.sidebar.header("B·ªô l·ªçc d·ªØ li·ªáu")
years = st.sidebar.multiselect("Ch·ªçn nƒÉm", options=data['Year'].dropna().unique(), default=data['Year'].dropna().unique())
date_range = st.sidebar.date_input(
    "Ch·ªçn kho·∫£ng th·ªùi gian",
    value=(data['Time_Close'].min(), data['Time_Close'].max()),
    min_value=data['Time_Close'].min(),
    max_value=data['Time_Close'].max(),
)
start_date = datetime.datetime.combine(date_range[0], datetime.time.min)
end_date = datetime.datetime.combine(date_range[1], datetime.time.max)
filtered_data = data[(data['Year'].isin(years)) & (data['Time_Close'].between(start_date, end_date))]

@st.cache_data
def load_model_outputs():
    # predictions = load_data_from_minio("data/Ingestion/predictions.csv")
    # feature_importance = load_data_from_minio("data/Ingestion/feature_importance.csv")
    # response = s3.get_object(Bucket=MINIO_BUCKET, Key="data/Ingestion/metrics.txt")
    predictions = load_data_from_minio("data/Ingestion/predictions_1.csv")
    feature_importance = load_data_from_minio("data/Ingestion/feature_importance_1.csv")
    response = s3.get_object(Bucket=MINIO_BUCKET, Key="data/Ingestion/metrics_1.txt")
    metrics = response['Body'].read().decode('utf-8').splitlines()
    mse = float(metrics[0].split(": ")[1])
    r2 = float(metrics[1].split(": ")[1])
    return predictions, feature_importance, mse, r2

refresh_interval = 10  # seconds
placeholder = st.empty()

while True:
    with placeholder.container():
        predictions, feature_importance, mse, r2 = load_model_outputs()

        key_suffix = str(int(time.time()))

        st.header("Bi·ªÉu di·ªÖn s·ª± ph√¢n t√°n sai l·ªách d·ª± ƒëo√°n")
        fig_actual_vs_pred = plt.figure(figsize=(8, 6))
        plt.scatter(predictions["True Values"], predictions["Predicted Values"], alpha=0.6, label="ƒêi·ªÉm bi·ªÉu di·ªÖn")
        plt.plot([predictions["True Values"].min(), predictions["True Values"].max()],
                 [predictions["True Values"].min(), predictions["True Values"].max()],
                 color="red", label="ƒê∆∞·ªùng l√Ω t∆∞·ªüng")
        plt.title("Bi·ªÉu di·ªÖn s·ª± ph√¢n t√°n sai l·ªách d·ª± ƒëo√°n")
        plt.xlabel("Gi√° tr·ªã th·ª±c")
        plt.ylabel("Gi√° tr·ªã d·ª± ƒëo√°n")
        plt.legend()
        st.pyplot(fig_actual_vs_pred)

        st.header("Ph√¢n Ph·ªëi Ph·∫ßn D∆∞")
        fig_residuals = plt.figure(figsize=(8, 6))
        plt.hist(predictions["Residuals"], bins=30, alpha=0.7, color="blue")
        plt.title("Ph√¢n Ph·ªëi Ph·∫ßn D∆∞")
        plt.xlabel("Residuals")
        plt.ylabel("Frequency")
        st.pyplot(fig_residuals)

        st.header("ƒê√°nh gi√° M√¥ H√¨nh")
        col1, col2 = st.columns(2)
        col1.metric("L·ªói Trung B√¨nh B√¨nh Ph∆∞∆°ng (MSE)", f"{mse:.2f}")
        col2.metric("H·ªá S·ªë X√°c ƒê·ªãnh (R¬≤)", f"{r2:.2f}")


        st.header("T√≠nh Quan Tr·ªçng C·ªßa ƒê·∫∑c Tr∆∞ng")

        top_features = feature_importance.sort_values(by="Importance", ascending=False).head(20)

        fig_feature_importance = plt.figure(figsize=(8, 6))
        plt.barh(top_features["Feature"], top_features["Importance"], color="green", alpha=0.7)
        plt.title("Top 10 ƒê·∫∑c Tr∆∞ng Quan Tr·ªçng")
        plt.xlabel("ƒê·ªô Quan Tr·ªçng")
        plt.ylabel("ƒê·∫∑c Tr∆∞ng")
        plt.gca().invert_yaxis() 
        st.pyplot(fig_feature_importance)


        st.write(f"üîÑ Dashboard c·∫≠p nh·∫≠t l√∫c: {time.strftime('%Y-%m-%d %H:%M:%S')}")

    time.sleep(refresh_interval)
